# 🤖🎤 Emotional Cognition Through Voice Tone Analysis  

Enhancing **human-robot interactions** through emotional cognition is pivotal for creating **intuitive** and **responsive** robotic systems. This study explores how **voice tone** can serve as a reliable indicator of emotional states, specifically distinguishing between **angry 😡** and **neutral 😐** emotions.  

## 📌 Overview  
Building on existing research in **affective computing** and **machine learning**, we analyze key acoustic features such as:  

- 🎼 **Spectral Centroid Mean**  
- 🎵 **Spectral Bandwidth Mean**  
- 🔊 **RMS Mean**  
- 🔁 **Zero-Crossing Rate Mean**  
- 🎚️ **Spectral Contrast Mean**  
- 🎤 **Pitch Mean**  
- 📈 **Pitch Confidence Mean**  
- 🌀 **Mel Spectrogram Mean**  
- 📊 **Mel Spectrogram Variance**  
- ⚡ **Energy Mean**  

### 🔍 Confusion Matrix  
![Confusion Matrix](https://github.com/hishamikoo/Emotional-Cognition-Through-Voice-Tone-Analysis/blob/main/confusion_matrix.png)  


Our experimental design involves analyzing **two types of audio samples**, angry and neutral tones, which were **normalized**, processed through **PCA**, and evaluated using **machine learning models** for emotion detection.  

## 🔬 Key Findings  
📈 The study reveals **significant differences** in acoustic metrics:  

✅ Angry samples exhibit **higher spectral centroid and bandwidth values**  
✅ Increased **loudness** and **noisiness** in angry tones compared to neutral ones  
✅ These distinct vocal features enable robots to **adapt responses accordingly**  

Such capabilities are crucial for applications in **healthcare 🏥**, **customer service 📞**, and **personal assistance 🤖**, where **empathetic** and **context-aware** interactions enhance the overall user experience.  

## 📊 Model Performance & Results  
### 📈 Model Performance  
![Model Performance](https://github.com/hishamikoo/Emotional-Cognition-Through-Voice-Tone-Analysis/blob/main/results.png)  

## 📂 Dataset & Research Paper  
📌 **Dataset**: [Click here to access the dataset 📊](https://github.com/hishamikoo/Emotional-Cognition-Through-Voice-Tone-Analysis/blob/main/cr_dataset.xlsx)  
📌 **Full Research Paper**: [Read the detailed study 📑](https://github.com/hishamikoo/Emotional-Cognition-Through-Voice-Tone-Analysis/blob/main/Emotional%20Cognition%20Through%20Voice%20Tone%20Analysis.pdf)  

## 🚀 Contribution to AI & Robotics  
This research contributes to the development of **emotionally intelligent robotic systems**, bridging the gap between **functional support** and **meaningful engagement** in human-robot collaborations. By enabling robots to **recognize** and **respond** to emotional cues, we move closer to **truly adaptive AI-driven interactions**.  

🌟 Stay tuned for more updates in this exciting field!  
