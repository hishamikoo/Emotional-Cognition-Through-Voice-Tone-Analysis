# ğŸ¤–ğŸ¤ Emotional Cognition Through Voice Tone Analysis  

Enhancing **human-robot interactions** through emotional cognition is pivotal for creating **intuitive** and **responsive** robotic systems. This study explores how **voice tone** can serve as a reliable indicator of emotional states, specifically distinguishing between **angry ğŸ˜¡** and **neutral ğŸ˜** emotions.  

## ğŸ“Œ Overview  
Building on existing research in **affective computing** and **machine learning**, we analyze key acoustic features such as:  

- ğŸ¼ **Spectral Centroid Mean**  
- ğŸµ **Spectral Bandwidth Mean**  
- ğŸ”Š **RMS Mean**  
- ğŸ” **Zero-Crossing Rate Mean**  
- ğŸšï¸ **Spectral Contrast Mean**  
- ğŸ¤ **Pitch Mean**  
- ğŸ“ˆ **Pitch Confidence Mean**  
- ğŸŒ€ **Mel Spectrogram Mean**  
- ğŸ“Š **Mel Spectrogram Variance**  
- âš¡ **Energy Mean**  

### ğŸ” Confusion Matrix  
![Confusion Matrix](https://github.com/hishamikoo/Emotional-Cognition-Through-Voice-Tone-Analysis/blob/main/confusion_matrix.png)  


Our experimental design involves analyzing **two types of audio samples**, angry and neutral tones, which were **normalized**, processed through **PCA**, and evaluated using **machine learning models** for emotion detection.  

## ğŸ”¬ Key Findings  
ğŸ“ˆ The study reveals **significant differences** in acoustic metrics:  

âœ… Angry samples exhibit **higher spectral centroid and bandwidth values**  
âœ… Increased **loudness** and **noisiness** in angry tones compared to neutral ones  
âœ… These distinct vocal features enable robots to **adapt responses accordingly**  

Such capabilities are crucial for applications in **healthcare ğŸ¥**, **customer service ğŸ“**, and **personal assistance ğŸ¤–**, where **empathetic** and **context-aware** interactions enhance the overall user experience.  

## ğŸ“Š Model Performance & Results  
### ğŸ“ˆ Model Performance  
![Model Performance](https://github.com/hishamikoo/Emotional-Cognition-Through-Voice-Tone-Analysis/blob/main/results.png)  

## ğŸ“‚ Dataset & Research Paper  
ğŸ“Œ **Dataset**: [Click here to access the dataset ğŸ“Š](https://github.com/hishamikoo/Emotional-Cognition-Through-Voice-Tone-Analysis/blob/main/cr_dataset.xlsx)  
ğŸ“Œ **Full Research Paper**: [Read the detailed study ğŸ“‘](https://github.com/hishamikoo/Emotional-Cognition-Through-Voice-Tone-Analysis/blob/main/Emotional%20Cognition%20Through%20Voice%20Tone%20Analysis.pdf)  

## ğŸš€ Contribution to AI & Robotics  
This research contributes to the development of **emotionally intelligent robotic systems**, bridging the gap between **functional support** and **meaningful engagement** in human-robot collaborations. By enabling robots to **recognize** and **respond** to emotional cues, we move closer to **truly adaptive AI-driven interactions**.  

ğŸŒŸ Stay tuned for more updates in this exciting field!  
